{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_smile_intensity(landmarks, image_width, image_height):\n",
    "    left = landmarks[61]\n",
    "    right = landmarks[291]\n",
    "    top = landmarks[13]\n",
    "    bottom = landmarks[14]\n",
    "\n",
    "    def denorm(pt):\n",
    "        return np.array([pt.x * image_width, pt.y * image_height])\n",
    "\n",
    "    left_pt = denorm(left)\n",
    "    right_pt = denorm(right)\n",
    "    top_pt = denorm(top)\n",
    "    bottom_pt = denorm(bottom)\n",
    "\n",
    "    mouth_width = np.linalg.norm(right_pt - left_pt)\n",
    "    mouth_height = np.linalg.norm(bottom_pt - top_pt)\n",
    "\n",
    "    if mouth_width == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    intensity = (mouth_height / mouth_width) * 2.0\n",
    "    return round(intensity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_eye_contact(landmarks, image_width, image_height, threshold=0.15):\n",
    "    def denorm(pt):\n",
    "        return np.array([pt.x * image_width, pt.y * image_height])\n",
    "    left_eye_outer = denorm(landmarks[33])\n",
    "    left_eye_inner = denorm(landmarks[133])\n",
    "    left_iris = denorm(landmarks[468])\n",
    "\n",
    "    right_eye_inner = denorm(landmarks[362])\n",
    "    right_eye_outer = denorm(landmarks[263])\n",
    "    right_iris = denorm(landmarks[473])\n",
    "\n",
    "    left_eye_width = np.linalg.norm(left_eye_outer - left_eye_inner)\n",
    "    right_eye_width = np.linalg.norm(right_eye_outer - right_eye_inner)\n",
    "\n",
    "    left_eye_center = (left_eye_outer + left_eye_inner) / 2\n",
    "    right_eye_center = (right_eye_outer + right_eye_inner) / 2\n",
    "\n",
    "    left_offset = np.linalg.norm(left_iris - left_eye_center) / left_eye_width\n",
    "    right_offset = np.linalg.norm(right_iris - right_eye_center) / right_eye_width\n",
    "\n",
    "    avg_offset = (left_offset + right_offset) / 2\n",
    "    \n",
    "    return avg_offset < threshold, round(avg_offset, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_eye_gaze_direction(landmarks, image_width, image_height, side=\"left\"):\n",
    "    def denorm(pt):\n",
    "        return np.array([pt.x * image_width, pt.y * image_height])\n",
    "\n",
    "    if side == \"left\":\n",
    "        outer = denorm(landmarks[33])\n",
    "        inner = denorm(landmarks[133])\n",
    "        iris = denorm(landmarks[468])\n",
    "    else:\n",
    "        outer = denorm(landmarks[263])\n",
    "        inner = denorm(landmarks[362])\n",
    "        iris = denorm(landmarks[473])\n",
    "\n",
    "    eye_width = np.linalg.norm(outer - inner)\n",
    "    if eye_width == 0:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    eye_center = (outer + inner) / 2\n",
    "    iris_offset = (iris - eye_center)[0]  \n",
    "\n",
    "    normalized_offset = iris_offset / eye_width\n",
    "\n",
    "    if normalized_offset < -0.12:\n",
    "        return \"Right\"  \n",
    "    elif normalized_offset > 0.12:\n",
    "        return \"Left\"   \n",
    "    else:\n",
    "        return \"Center\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def detect_blink(landmarks, image_width, image_height, prev_state, threshold=0.22):\n",
    "    def denorm(pt): return np.array([pt.x * image_width, pt.y * image_height])\n",
    "\n",
    "    top = denorm(landmarks[159])\n",
    "    bottom = denorm(landmarks[145])\n",
    "    left = denorm(landmarks[33])\n",
    "    right = denorm(landmarks[133])\n",
    "\n",
    "    vertical = np.linalg.norm(top - bottom)\n",
    "    horizontal = np.linalg.norm(left - right)\n",
    "\n",
    "    if horizontal == 0:\n",
    "        return False, prev_state\n",
    "\n",
    "    ear = vertical / horizontal\n",
    "\n",
    "    if ear < threshold and prev_state == \"open\":\n",
    "        return True, \"closed\"\n",
    "    elif ear >= threshold:\n",
    "        return False, \"open\"\n",
    "    else:\n",
    "        return False, prev_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_head_position(landmarks, w, h, threshold=10):\n",
    "    left_eye_outer = np.array([landmarks[33].x * w, landmarks[33].y * h])\n",
    "    right_eye_outer = np.array([landmarks[263].x * w, landmarks[263].y * h])\n",
    "\n",
    "    dx = right_eye_outer[0] - left_eye_outer[0]\n",
    "    dy = right_eye_outer[1] - left_eye_outer[1]\n",
    "    angle = np.degrees(np.arctan2(dy, dx))  \n",
    "\n",
    "    tilt_score = max(0, 1 - abs(angle) / threshold)\n",
    "    tilt_score = round(min(tilt_score, 1.0), 2)\n",
    "\n",
    "    return tilt_score, round(angle, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_smile(smile_intensity):\n",
    "    if smile_intensity > 0.4:\n",
    "        return 1.0\n",
    "    elif smile_intensity > 0.25:\n",
    "        return 0.7\n",
    "    elif smile_intensity > 0.15:\n",
    "        return 0.4\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def score_eye_contact(eye_contact):\n",
    "    return 1.0 if eye_contact else 0.0\n",
    "\n",
    "def score_gaze(gaze_direction):\n",
    "    if gaze_direction == \"Center\":\n",
    "        return 1.0\n",
    "    elif gaze_direction == \"Uncertain\":\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def score_blink_rate(blink_rate):\n",
    "    if 10 <= blink_rate <= 25:\n",
    "        return 1.0\n",
    "    elif 6 <= blink_rate <= 30:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0\n",
    "def score_head_position(head_score):\n",
    "    return head_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_confidence(smile_intensity, eye_contact, gaze_direction, blink_rate, head_pos):\n",
    "    s = score_smile(smile_intensity)\n",
    "    e = score_eye_contact(eye_contact)\n",
    "    g = score_gaze(gaze_direction)\n",
    "    b = score_blink_rate(blink_rate)\n",
    "    h = score_head_position(head_pos)\n",
    "\n",
    "    final_score = (0.22 * s) + (0.25 * e) + (0.20 * g) + (0.15 * b) + (0.18 * h)\n",
    "    return round(final_score * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def evaluate_confidence(smile_intensity, eye_contact, gaze_direction, blink_rate):\\n    s = score_smile(smile_intensity)\\n    e = score_eye_contact(eye_contact)\\n    g = score_gaze(gaze_direction)\\n    b = score_blink_rate(blink_rate)\\n\\n\\n    final_score = (0.25 * s) + (0.35 * e) + (0.25 * g) + (0.15 * b)\\n    return round(final_score * 100)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def evaluate_confidence(smile_intensity, eye_contact, gaze_direction, blink_rate):\n",
    "    s = score_smile(smile_intensity)\n",
    "    e = score_eye_contact(eye_contact)\n",
    "    g = score_gaze(gaze_direction)\n",
    "    b = score_blink_rate(blink_rate)\n",
    "\n",
    "\n",
    "    final_score = (0.25 * s) + (0.35 * e) + (0.25 * g) + (0.15 * b)\n",
    "    return round(final_score * 100)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 104\u001b[0m\n\u001b[0;32m     99\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfidence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfidence_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m180\u001b[39m),\n\u001b[0;32m    100\u001b[0m                     cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.7\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m100\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    101\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconf_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m210\u001b[39m),\n\u001b[0;32m    102\u001b[0m                     cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.7\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m150\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 104\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReal-time Confidence Estimator\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "blink_count = 0\n",
    "blink_state = \"open\"\n",
    "start_time = time.time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            h, w, _ = frame.shape\n",
    "            landmarks = face_landmarks.landmark\n",
    "\n",
    "            # Smile\n",
    "            intensity = calculate_smile_intensity(landmarks, w, h)\n",
    "            if intensity < 0.15:\n",
    "                smile_label = \"No Smile\"\n",
    "            elif intensity < 0.25:\n",
    "                smile_label = \"Light Smile\"\n",
    "            elif intensity < 0.4:\n",
    "                smile_label = \"Moderate Smile\"\n",
    "            else:\n",
    "                smile_label = \"Big Smile\"\n",
    "\n",
    "            cv2.putText(frame, f\"Smile Intensity: {intensity} ({smile_label})\",\n",
    "                        (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "            # Eye Contact\n",
    "            eye_contact, offset = check_eye_contact(landmarks, w, h)\n",
    "            eye_label = \"Looking at Camera\" if eye_contact else \"Not Looking\"\n",
    "            eye_color = (0, 200, 0) if eye_contact else (0, 0, 200)\n",
    "\n",
    "            cv2.putText(frame, f\"Eye Contact: {eye_label} (Offset: {offset})\",\n",
    "                        (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, eye_color, 2)\n",
    "\n",
    "            # Gaze Direction\n",
    "            left_gaze = get_eye_gaze_direction(landmarks, w, h, side=\"left\")\n",
    "            right_gaze = get_eye_gaze_direction(landmarks, w, h, side=\"right\")\n",
    "            gaze_label = left_gaze if left_gaze == right_gaze else \"Uncertain\"\n",
    "            gaze_score = 1.0 if gaze_label == \"Center\" else 0.5 if gaze_label != \"Uncertain\" else 0.0\n",
    "\n",
    "            cv2.putText(frame, f\"Gaze: {gaze_label}\",\n",
    "                        (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "\n",
    "            # Blink Detection\n",
    "            blink, blink_state = detect_blink(landmarks, w, h, blink_state)\n",
    "            if blink:\n",
    "                blink_count += 1\n",
    "\n",
    "            elapsed_minutes = (time.time() - start_time) / 60\n",
    "            blink_rate = blink_count / elapsed_minutes if elapsed_minutes > 0 else 0\n",
    "            blink_score = 1.0 if 10 <= blink_rate <= 25 else 0.5 if blink_rate < 40 else 0.2  # Adjust ranges if needed\n",
    "\n",
    "            cv2.putText(frame, f\"Blinks: {blink_count}\", (30, 120),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 100, 255), 2)\n",
    "            cv2.putText(frame, f\"Blink Rate: {blink_rate:.2f} blinks/min\", (30, 150),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (150, 255, 150), 2)\n",
    "\n",
    "            # Head Position\n",
    "            score_head, head_angle = check_head_position(landmarks, w, h)\n",
    "\n",
    "            cv2.putText(frame, f\"Head Tilt Angle: {head_angle}Â°\", (30, 240),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (100, 255, 255), 2)\n",
    "\n",
    "            # Confidence Evaluation\n",
    "            confidence_score = evaluate_confidence(\n",
    "                smile_intensity=intensity,\n",
    "                eye_contact=1.0 if eye_contact else 0.0,\n",
    "                gaze_direction=gaze_score,\n",
    "                blink_rate=blink_score,\n",
    "                head_pos=score_head\n",
    "            )\n",
    "\n",
    "            # Label\n",
    "            if confidence_score > 75:\n",
    "                conf_label = \"High Confidence\"\n",
    "            elif confidence_score > 50:\n",
    "                conf_label = \"Moderate Confidence\"\n",
    "            else:\n",
    "                conf_label = \"Low Confidence\"\n",
    "\n",
    "            cv2.putText(frame, f\"Confidence: {confidence_score}%\", (30, 180),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 200, 100), 2)\n",
    "            cv2.putText(frame, f\"Evaluation: {conf_label}\", (30, 210),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 150), 2)\n",
    "\n",
    "    cv2.imshow('Real-time Confidence Estimator', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import os\n",
    "\n",
    "def extract_audio(video_path, audio_path):\n",
    "    ffmpeg.input(video_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio extraction failed:\n",
      "ffmpeg stderr: ffmpeg version 7.1.1-essentials_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 14.2.0 (Rev1, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "[in#0 @ 0000016e3c2457c0] Error opening input: No such file or directory\n",
      "Error opening input file media\\video_sample.mp4.\n",
      "Error opening input files: No such file or directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ffmpeg\n",
    "import os\n",
    "\n",
    "def extract_audio(video_path, audio_path):\n",
    "    try:\n",
    "        out, err = ffmpeg.input(video_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True, capture_stdout=True, capture_stderr=True)\n",
    "        print('Audio extraction succeeded.')\n",
    "        print('ffmpeg stdout:', out.decode('utf-8') if out else '')\n",
    "        print('ffmpeg stderr:', err.decode('utf-8') if err else '')\n",
    "    except ffmpeg.Error as e:\n",
    "        print('Audio extraction failed:')\n",
    "        print('ffmpeg stderr:', e.stderr.decode('utf-8') if e.stderr else str(e))\n",
    "\n",
    "video_path = 'media\\\\video_sample.mp4'\n",
    "audio_path = 'media\\\\extracted_audio\\\\audio_sample.wav'\n",
    "extract_audio(video_path=video_path, audio_path=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m video_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedia\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_sample.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(video_path)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(video_path))\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "video_path = os.path.join(os.path.dirname(__file__), 'media', 'video_sample.mp4')\n",
    "print(video_path)\n",
    "print(os.path.isfile(video_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m video_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedia\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_sample.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(video_path))\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "video_path = os.path.join(os.path.dirname(__file__), 'media','video_sample.mp4')\n",
    "print(os.path.isfile(video_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import cv2\\nimport mediapipe as mp\\nimport time\\n\\nmp_face_mesh = mp.solutions.face_mesh\\nface_mesh = mp_face_mesh.FaceMesh(\\n    static_image_mode=False,\\n    max_num_faces=1,\\n    refine_landmarks=True\\n)\\nmp_drawing = mp.solutions.drawing_utils\\n\\ncap = cv2.VideoCapture(0)\\n\\nblink_count = 0\\nblink_state = \"open\"\\nstart_time = time.time()\\n\\nwhile cap.isOpened():\\n    success, frame = cap.read()\\n    if not success:\\n        break\\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\\n    results = face_mesh.process(frame_rgb)\\n\\n    if results.multi_face_landmarks:\\n        for face_landmarks in results.multi_face_landmarks:\\n            h, w, _ = frame.shape\\n            landmarks = face_landmarks.landmark\\n\\n            # Smile\\n            intensity = calculate_smile_intensity(landmarks, w, h)\\n            if intensity < 0.15:\\n                smile_label = \"No Smile\"\\n            elif intensity < 0.25:\\n                smile_label = \"Light Smile\"\\n            elif intensity < 0.4:\\n                smile_label = \"Moderate Smile\"\\n            else:\\n                smile_label = \"Big Smile\"\\n\\n            cv2.putText(frame, f\"Smile Intensity: {intensity} ({smile_label})\",\\n                        (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\\n\\n            # Eye Contact\\n            eye_contact, offset = check_eye_contact(landmarks, w, h)\\n            eye_label = \"Looking at Camera\" if eye_contact else \"Not Looking\"\\n            eye_color = (0, 200, 0) if eye_contact else (0, 0, 200)\\n\\n            cv2.putText(frame, f\"Eye Contact: {eye_label} (Offset: {offset})\",\\n                        (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, eye_color, 2)\\n\\n            # Gaze Direction\\n            left_gaze = get_eye_gaze_direction(landmarks, w, h, side=\"left\")\\n            right_gaze = get_eye_gaze_direction(landmarks, w, h, side=\"right\")\\n            gaze_label = left_gaze if left_gaze == right_gaze else \"Uncertain\"\\n\\n            cv2.putText(frame, f\"Gaze: {gaze_label}\",\\n                        (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\\n\\n            # Blink Detection\\n            blink, blink_state = detect_blink(landmarks, w, h, blink_state)\\n            if blink:\\n                blink_count += 1\\n\\n            elapsed_minutes = (time.time() - start_time) / 60\\n            blink_rate = blink_count / elapsed_minutes if elapsed_minutes > 0 else 0\\n\\n            cv2.putText(frame, f\"Blinks: {blink_count}\", (30, 120),\\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 100, 255), 2)\\n            cv2.putText(frame, f\"Blink Rate: {blink_rate:.2f} blinks/min\", (30, 150),\\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (150, 255, 150), 2)\\n\\n            # Confidence Evaluation\\n            confidence_score = evaluate_confidence(\\n                smile_intensity=intensity,\\n                eye_contact=eye_contact,\\n                gaze_direction=gaze_label,\\n                blink_rate=blink_rate\\n            )\\n\\n            # Label\\n            if confidence_score > 75:\\n                conf_label = \"High Confidence\"\\n            elif confidence_score > 50:\\n                conf_label = \"Moderate Confidence\"\\n            else:\\n                conf_label = \"Low Confidence\"\\n\\n            cv2.putText(frame, f\"Confidence: {confidence_score}%\", (30, 180),\\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 200, 100), 2)\\n            cv2.putText(frame, f\"Evaluation: {conf_label}\", (30, 210),\\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 150), 2)\\n\\n\\n    cv2.imshow(\\'Real-time Confidence Estimator\\', frame)\\n    if cv2.waitKey(1) & 0xFF == 27:\\n        break\\n\\ncap.release()\\ncv2.destroyAllWindows()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "blink_count = 0\n",
    "blink_state = \"open\"\n",
    "start_time = time.time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            h, w, _ = frame.shape\n",
    "            landmarks = face_landmarks.landmark\n",
    "\n",
    "            # Smile\n",
    "            intensity = calculate_smile_intensity(landmarks, w, h)\n",
    "            if intensity < 0.15:\n",
    "                smile_label = \"No Smile\"\n",
    "            elif intensity < 0.25:\n",
    "                smile_label = \"Light Smile\"\n",
    "            elif intensity < 0.4:\n",
    "                smile_label = \"Moderate Smile\"\n",
    "            else:\n",
    "                smile_label = \"Big Smile\"\n",
    "\n",
    "            cv2.putText(frame, f\"Smile Intensity: {intensity} ({smile_label})\",\n",
    "                        (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "            # Eye Contact\n",
    "            eye_contact, offset = check_eye_contact(landmarks, w, h)\n",
    "            eye_label = \"Looking at Camera\" if eye_contact else \"Not Looking\"\n",
    "            eye_color = (0, 200, 0) if eye_contact else (0, 0, 200)\n",
    "\n",
    "            cv2.putText(frame, f\"Eye Contact: {eye_label} (Offset: {offset})\",\n",
    "                        (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, eye_color, 2)\n",
    "\n",
    "            # Gaze Direction\n",
    "            left_gaze = get_eye_gaze_direction(landmarks, w, h, side=\"left\")\n",
    "            right_gaze = get_eye_gaze_direction(landmarks, w, h, side=\"right\")\n",
    "            gaze_label = left_gaze if left_gaze == right_gaze else \"Uncertain\"\n",
    "\n",
    "            cv2.putText(frame, f\"Gaze: {gaze_label}\",\n",
    "                        (30, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "\n",
    "            # Blink Detection\n",
    "            blink, blink_state = detect_blink(landmarks, w, h, blink_state)\n",
    "            if blink:\n",
    "                blink_count += 1\n",
    "\n",
    "            elapsed_minutes = (time.time() - start_time) / 60\n",
    "            blink_rate = blink_count / elapsed_minutes if elapsed_minutes > 0 else 0\n",
    "\n",
    "            cv2.putText(frame, f\"Blinks: {blink_count}\", (30, 120),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 100, 255), 2)\n",
    "            cv2.putText(frame, f\"Blink Rate: {blink_rate:.2f} blinks/min\", (30, 150),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (150, 255, 150), 2)\n",
    "\n",
    "            # Confidence Evaluation\n",
    "            confidence_score = evaluate_confidence(\n",
    "                smile_intensity=intensity,\n",
    "                eye_contact=eye_contact,\n",
    "                gaze_direction=gaze_label,\n",
    "                blink_rate=blink_rate\n",
    "            )\n",
    "\n",
    "            # Label\n",
    "            if confidence_score > 75:\n",
    "                conf_label = \"High Confidence\"\n",
    "            elif confidence_score > 50:\n",
    "                conf_label = \"Moderate Confidence\"\n",
    "            else:\n",
    "                conf_label = \"Low Confidence\"\n",
    "\n",
    "            cv2.putText(frame, f\"Confidence: {confidence_score}%\", (30, 180),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 200, 100), 2)\n",
    "            cv2.putText(frame, f\"Evaluation: {conf_label}\", (30, 210),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 150), 2)\n",
    "\n",
    "\n",
    "    cv2.imshow('Real-time Confidence Estimator', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
